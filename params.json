{"name":"Stock Inference","tagline":"Stock inference engine using Apache Geode, SpringXD, Zeppelin and Spark ML Lib.","body":"# Stock Prediction with Machine Learning \r\n\r\n![Architecture](StockInference-arch.png)\r\n\r\n\r\n## Summary\r\n\r\nStock Inference engine using Spring XD, Apache Geode / GemFire and Spark ML Lib.\r\n\r\n## Requirements\r\n\r\n* [Apache Geode (Incubating)](http://geode.incubator.apache.org/) or [Pivotal GemFire](http://pivotal.io/big-data/pivotal-gemfire)\r\n* [Spring XD 1.2+](http://projects.spring.io/spring-xd/)\r\n* [Apache Spark 1.3.1](http://spark.apache.org/downloads.html)\r\n* [Apache Zeppelin (Incubating)](http://zeppelin.incubator.apache.org/)\r\n* 8GB+ RAM (recommended)\r\n* Linux or OSX (Windows should be OK but instructions assume *nix shell)\r\n\r\n\r\nps: If you are were given a pre-packaged Vagrant VM for this lab you'll only need:\r\n\r\n* [VirtualBox 4.3+ or 5.0](https://www.virtualbox.org/wiki/Downloads)\r\n* [Vagrant](https://www.vagrantup.com/downloads.html)\r\n\r\nif you prefer to create a demo VM yourself, the instructions are [here](VM.md)\r\n\r\n## First steps with each product\r\n\r\nIf you're not familiar with Geode/GemFire, Spring XD, Spark ML and Apache Zeppelin, please first follow the product specific labs below:\r\n\r\n* [First steps with Apache Geode](Geode.md)\r\n* [First steps with SpringXD Lab](SpringXD.md)\r\n* [First steps with Spark ML](SparkML.md)\r\n* [First steps with Apache Zeppelin](Zeppelin.md)\r\n\r\n\r\n\r\n### Starting the demo environment\r\n\r\nIf you have received a pre-built Virtual Machine, start the VM and access its console using ssh as below:\r\n\r\n```\r\n$ vagrant up\r\n\r\nBringing machine 'default' up with 'virtualbox' provider...\r\n==> default: Box 'package.box' could not be found. Attempting to find and install...\r\n    default: Box Provider: virtualbox\r\n    default: Box Version: >= 0\r\n==> default: Adding box 'package.box' (v0) for provider: virtualbox\r\n    default: Downloading: file:///Users/fmelo/qcon/package.box\r\n==> default: Successfully added box 'package.box' (v0) for 'virtualbox'!\r\n(...)\r\n    default: Running: inline script\r\n==> default: stdin: is not a tty\r\n==> default: QCon Rio 2015 - Pivotal Lab\r\n\r\n$ vagrant ssh\r\nWelcome to Ubuntu 15.04 (GNU/Linux 3.19.0-23-generic x86_64)\r\n\r\n * Documentation:  https://help.ubuntu.com/\r\n\r\n  System information as of Mon Aug 24 01:13:06 UTC 2015\r\n\r\n  System load:  0.0                Processes:           96\r\n  Usage of /:   17.6% of 38.81GB   Users logged in:     0\r\n  Memory usage: 2%                 IP address for eth0: 10.0.2.15\r\n  Swap usage:   0%                 IP address for eth1: 192.168.56.10\r\n\r\n  Graph this data and manage this system at:\r\n    https://landscape.canonical.com/\r\n\r\n  Get cloud support with Ubuntu Advantage Cloud Guest:\r\n    http://www.ubuntu.com/business/services/cloud\r\n\r\n47 packages can be updated.\r\n27 updates are security updates.\r\n\r\n\r\nLast login: Sun Aug 23 23:16:30 2015 from 10.0.2.2\r\n_____________________________________________________________________________\r\n\r\nLab variables:\r\nGEODE_HOME=/home/vagrant/incubator-geode/gemfire-assembly/build/install/apache-geode\r\nSPRINGXD_HOME=/home/vagrant/spring-xd-2.0.0.BUILD-SNAPSHOT\r\nZEPPELIN_HOME=/home/vagrant/incubator-zeppelin\r\nSPARK_HOME=/home/vagrant/spark-1.3.1-bin-hadoop2.6\r\nPROJECT=/home/vagrant/project/StockInference-Spark\r\n\r\n_____________________________________________________________________________\r\n\r\n[vagrant@stocks-vm, load: 0.00] (Mon Aug 24 - 01:13:10)\r\n~ $\r\n```\r\n\r\n\r\n### Creating the Geode / GemFire regions \r\n\r\nThe demo uses three different regions for storing data:\r\n* /Stocks - Stores raw stock trading data, as acquired from [Yahoo Finance YQL](finance.yahoo.com) or using the simulator (which randomly replays data previously ingested from the same Yahoo Finance YQL)\r\n* /TechIndicators - Stores technical indicators, which will be used as inputs / features to the Machine Learning model. The indicators are calculated by the [R script](streaming/tech_indicators.R), which is involked by Spring XD.\r\n* /Predictions - Stores the predicted data, as it gets calculated by the [Spark MLLib model](StockInference/src/main/scala/io/pivotal/demo/StockInferenceDemo.scala).\r\n\r\nTo create the regions, execute the script `startGeode.sh` under the `data` folder of this project root path as below:\r\n\r\n```\r\n$ cd project/StockInference-Spark/data\r\n$ ./startGeode.sh\r\n\r\n1. Executing - start locator --name=locator1 --J=-Dgemfire.http-service-port=7575\r\n\r\n............................................\r\nLocator in /home/vagrant/project/StockInference-Spark/data/locator1 on 192.168.56.10[10334] as locator1 is currently online.\r\nProcess ID: 4374\r\nUptime: 23 seconds\r\nGemFire Version: 1.0.0-incubating-SNAPSHOT\r\nJava Version: 1.8.0_51\r\nLog File: /home/vagrant/project/StockInference-Spark/data/locator1/locator1.log\r\nJVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.http-service-port=7575 -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806\r\nClass-Path: /home/vagrant/incubator-geode/gemfire-assembly/build/install/apache-geode/lib/gemfire-core-1.0.0-incubating-SNAPSHOT.jar:/home/vagrant/incubator-geode/gemfire-assembly/build/install/apache-geode/lib/gemfire-core-dependencies.jar\r\n\r\nSuccessfully connected to: [host=192.168.56.10, port=1099]\r\n\r\nCluster configuration service is up and running.\r\n\r\n2. Executing - start server --name=server1 --J=-Dgemfire.start-dev-rest-api=true --J=-Dgemfire.http-service-port=8888\r\n\r\n..............\r\nServer in /home/vagrant/project/StockInference-Spark/data/server1 on 192.168.56.10[40404] as server1 is currently online.\r\nProcess ID: 4546\r\nUptime: 7 seconds\r\nGemFire Version: 1.0.0-incubating-SNAPSHOT\r\nJava Version: 1.8.0_51\r\nLog File: /home/vagrant/project/StockInference-Spark/data/server1/server1.log\r\nJVM Arguments: -Dgemfire.default.locators=192.168.56.10[10334] -Dgemfire.use-cluster-configuration=true -Dgemfire.start-dev-rest-api=true -Dgemfire.http-service-port=8888 -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806\r\nClass-Path: /home/vagrant/incubator-geode/gemfire-assembly/build/install/apache-geode/lib/gemfire-core-1.0.0-incubating-SNAPSHOT.jar:/home/vagrant/incubator-geode/gemfire-assembly/build/install/apache-geode/lib/gemfire-core-dependencies.jar\r\n\r\n3. Executing - create region --name=/Stocks --type=PARTITION\r\n\r\nMember  | Status\r\n------- | -------------------------------------\r\nserver1 | Region \"/Stocks\" created on \"server1\"\r\n\r\n4. Executing - create region --name=/TechIndicators --type=PARTITION\r\n\r\nMember  | Status\r\n------- | ---------------------------------------------\r\nserver1 | Region \"/TechIndicators\" created on \"server1\"\r\n\r\n5. Executing - create region --name=/Predictions --type=PARTITION\r\n\r\nMember  | Status\r\n------- | ------------------------------------------\r\nserver1 | Region \"/Predictions\" created on \"server1\"\r\n\r\n6. Executing - import data --region=/Stocks --file=../Stocks.gfd --member=server1\r\n\r\nData imported from file : /home/vagrant/project/StockInference-Spark/data/Stocks.gfd on host : 192.168.56.10 to region : /Stocks\r\n\r\n7. Executing - import data --region=/TechIndicators --file=../TechIndicators.gfd --member=server1\r\n\r\nData imported from file : /home/vagrant/project/StockInference-Spark/data/TechIndicators.gfd on host : 192.168.56.10 to region : /TechIndicators\r\n\r\n8. Executing - describe region --name=/Stocks\r\n\r\n..........................................................\r\nName            : Stocks\r\nData Policy     : partition\r\nHosting Members : server1\r\n\r\nNon-Default Attributes Shared By Hosting Members\r\n\r\n Type  |    Name     | Value\r\n------ | ----------- | ---------\r\nRegion | size        | 41540\r\n       | data-policy | PARTITION\r\n\r\n\r\n9. Executing - describe region --name=/TechIndicators\r\n\r\n..........................................................\r\nName            : TechIndicators\r\nData Policy     : partition\r\nHosting Members : server1\r\n\r\nNon-Default Attributes Shared By Hosting Members\r\n\r\n Type  |    Name     | Value\r\n------ | ----------- | ---------\r\nRegion | size        | 36486\r\n       | data-policy | PARTITION\r\n\r\n\r\n10. Executing - describe region --name=/Predictions\r\n\r\n..........................................................\r\nName            : Predictions\r\nData Policy     : partition\r\nHosting Members : server1\r\n\r\nNon-Default Attributes Shared By Hosting Members\r\n\r\n Type  |    Name     | Value\r\n------ | ----------- | ---------\r\nRegion | size        | 0\r\n       | data-policy | PARTITION\r\n```\r\nAs you can verify, the script not only created the regions but also imported some data we had captured earlier, in order to train our model. We'll keep re-training it later as we ingest data.\r\n\r\nNext, we should deploy the Geode/GemFire functions for the Spark Connector:\r\n\r\n```\r\n~/project/StockInference-Spark/data $ ./deployFunctionVM.sh\r\n\r\n(1) Executing - connect\r\n\r\nConnecting to Locator at [host=localhost, port=10334] ..\r\nConnecting to Manager at [host=192.168.56.10, port=1099] ..\r\nSuccessfully connected to: [host=192.168.56.10, port=1099]\r\n\r\n\r\n(2) Executing - deploy --jar=/home/vagrant/incubator-geode/gemfire-spark-connector/gemfire-functions/target/scala-2.10/gemfire-functions_2.10-0.5.0.jar\r\n\r\nMember  |           Deployed JAR           | Deployed JAR Location\r\n------- | -------------------------------- | ------------------------------------------------------------------------------------------------\r\nserver1 | gemfire-functions_2.10-0.5.0.jar | /home/vagrant/project/StockInference-Spark/data/server1/vf.gf#gemfire-functions_2.10-0.5.0.jar#1\r\n\r\n```\r\n\r\n\r\n### Training the Machine Learning model\r\n\r\nBefore executing the Machine Learning model on Spark, we need to train it with existing data.\r\nFor doing that, run the script below, which involkes the [scala class](StockInference/src/main/scala/io/pivotal/demo/StockInferenceDemo.scala) \r\n\r\nFrom the streaming folder, run ``train.sh`` . It will take a while for it to run.\r\n```\r\n~/project/StockInference-Spark $ cd streaming\r\n\r\n~/project/StockInference-Spark/streaming $ ./train.sh\r\n15/08/24 03:07:41 INFO SparkContext: Running Spark version 1.3.1\r\n15/08/24 03:07:41 WARN Utils: Your hostname, stocks-vm resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface eth0)\r\n(...)\r\n15/08/24 03:09:33 INFO DAGScheduler: Stage 2012 (mean at StockInferenceDemo.scala:127) finished in 0.072 s\r\n15/08/24 03:09:33 INFO DAGScheduler: Job 2012 finished: mean at StockInferenceDemo.scala:127, took 0.084467 s\r\ntraining Mean Squared Error = 4.356799628392633E-4\r\n[info 2015/08/24 03:09:33.493 UTC <Distributed system shutdown hook> tid=0x40] VM is exiting - shutting down distributed system\r\n\r\n[info 2015/08/24 03:09:33.498 UTC <Distributed system shutdown hook> tid=0x40] GemFireCache[id = 1756587746; isClosing = true; isShutDownAll = false; created = Mon Aug 24 03:07:48 UTC 2015; server = false; copyOnRead = false; lockLease = 120; lockTimeout = 60]: Now closing.\r\n\r\n[info 2015/08/24 03:09:33.555 UTC <Distributed system shutdown hook> tid=0x40] Destroying connection pool DEFAULT\r\n```\r\n\r\n\r\n### Creating the Spring XD streams\r\n\r\nNow we'll create the streams in SpringXD that orchestrate all the data flow.\r\n\r\nLet's first start Spring XD. From the ``streaming`` directory, run the script `startSpringXD.sh`. This will start the server in background, outputing the logs to the file ``nohup.out``\r\n\r\n```\r\n~/project/StockInference-Spark/streaming $ ./startSpringXD.sh\r\nStarting...\r\nnohup: appending output to ‘nohup.out’\r\n```\r\n\r\nNext, take a look at the file ``stream-create.xd``, containing the streams we'll create on Spring XD. Remember the  [architecture image](StockInference-arch.png)\r\n\r\n```\r\n~/project/StockInference-Spark/streaming $ more stream-create.xd\r\nadmin config server http://localhost:9393\r\n\r\nstream create process_sink --definition \"queue:stocks >  transform --script='file:./transform.groovy' | object-to-json | gemfire-json-server --useLocator=true --host=localhost --port\r\n=10334 --regionName=Stocks --keyExpression=payload.getField('entryTimestamp')\" --deploy\r\n\r\nstream create yahoo_finance_source --definition \"trigger --cron='* * 7-13 * * MON-FRI' | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select Symbol, LastTradeDate\r\n, LastTradeTime, LastTradePriceOnly, DaysHigh, DaysLow, Open from yahoo.finance.quotes where symbol in (\\\"TSLA\\\")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMe\r\nthod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote')  > queue:stocks\" --deploy\r\n\r\nstream create http_source --definition \"http --port=9000 | splitter --expression=#jsonPath(payload,'$') > queue:stocks\" --deploy\r\n\r\nstream create --name r_process --definition \"tap:stream:process_sink.transform > r-parsing: object-to-json | shell --command='Rscript ./tech_indicators.R' | formatting: splitter --ex\r\npression=#jsonPath(payload,'$') | filter --expression=#jsonPath(payload,'$.rsi').indexOf('NaN')==-1 | object-to-json | gemfire-json-server --useLocator=true --host=locator --port=103\r\n34 --regionName=TechIndicators --keyExpression=payload.getField('entryTimestamp')\" --deploy\r\n\r\nstream create --name prediction --definition \"tap:stream:r_process.object-to-json > shell --command='../evaluate.sh' | gemfire-json-server --regionName=Predictions --host=localhost -\r\n-port=10334 --useLocator=true --keyExpression=payload.getField('entryTimestamp')\" --deploy\r\n\r\n# stream create --name training --definition \"trigger --fixedDelay=300 | shell --command='../train.sh'\" --deploy\r\n```\r\n\r\nPlease note the ``yahoo_finance_source`` stream has a cron based on PDT timezone (7-13 MON-FRI = normal Wall Street operating times). If your environment has another timezone set, you'll need to adjust it accordingly.\r\n\r\nExecute the script ``stream-create.sh`` to deploy all streams to Spring XD:\r\n\r\n```\r\n~/project/StockInference-Spark/streaming $ ./stream-create.sh\r\nAug 24, 2015 3:19:48 AM org.springframework.shell.core.AbstractShell handleExecutionResult\r\nINFO: Successfully targeted http://localhost:9393\r\nAug 24, 2015 3:19:53 AM org.springframework.shell.core.AbstractShell handleExecutionResult\r\nINFO: Created and deployed new stream 'process_sink'\r\nAug 24, 2015 3:19:54 AM org.springframework.shell.core.AbstractShell handleExecutionResult\r\nINFO: Created and deployed new stream 'yahoo_finance_source'\r\nAug 24, 2015 3:19:55 AM org.springframework.shell.core.AbstractShell handleExecutionResult\r\nINFO: Created and deployed new stream 'http_source'\r\nAug 24, 2015 3:20:05 AM org.springframework.shell.core.AbstractShell handleExecutionResult\r\nINFO: Created and deployed new stream 'r_process'\r\nAug 24, 2015 3:20:08 AM org.springframework.shell.core.AbstractShell handleExecutionResult\r\nINFO: Created and deployed new stream 'prediction'\r\n```\r\n\r\nAt this point, Spring XD is already querying Yahoo Finance for the latest quotes(at the normal market hours), and also listening for possible quotes at port 9000. \r\n\r\n### Using the Simulator\r\n\r\nWhen you're not on US stock market open hours, we can use the simulator to randomly replay some of the old quotes stored on Geode / GemFire. As the order is random, we can expect a much higher volatility.\r\n\r\nStart the simulator from the ``FinanceStreamSimulator`` folder:\r\n\r\n```\r\n~/project/StockInference-Spark/FinanceStreamSimulator $ ./startSimulator.sh\r\n:compileJava UP-TO-DATE\r\n:processResources UP-TO-DATE\r\n:classes UP-TO-DATE\r\n:findMainClass\r\n:run\r\n  /$$$$$$$$ /$$            /$$$$$$   /$$                      /$$$$$$  /$$                         /$$             /$$\r\n| $$_____/|__/           /$$__  $$ | $$                     /$$__  $$|__/                        | $$            | $$\r\n| $$       /$$ /$$$$$$$ | $$  \\__//$$$$$$    /$$$$$$       | $$  \\__/ /$$ /$$$$$$/$$$$  /$$   /$$| $$  /$$$$$$  /$$$$$$    /$$$$$$   /$$$$$$\r\n| $$$$$   | $$| $$__  $$|  $$$$$$|_  $$_/   /$$__  $$      |  $$$$$$ | $$| $$_  $$_  $$| $$  | $$| $$ |____  $$|_  $$_/   /$$__  $$ /$$__  $$\r\n| $$__/   | $$| $$  \\ $$ \\____  $$ | $$    | $$  \\__/       \\____  $$| $$| $$ \\ $$ \\ $$| $$  | $$| $$  /$$$$$$$  | $$    | $$  \\ $$| $$  \\__/\r\n| $$      | $$| $$  | $$ /$$  \\ $$ | $$ /$$| $$             /$$  \\ $$| $$| $$ | $$ | $$| $$  | $$| $$ /$$__  $$  | $$ /$$| $$  | $$| $$\r\n| $$      | $$| $$  | $$|  $$$$$$/ |  $$$$/| $$            |  $$$$$$/| $$| $$ | $$ | $$|  $$$$$$/| $$|  $$$$$$$  |  $$$$/|  $$$$$$/| $$\r\n|__/      |__/|__/  |__/ \\______/   \\___/  |__/             \\______/ |__/|__/ |__/ |__/ \\______/ |__/ \\_______/   \\___/   \\______/ |__/\r\n\r\n\r\nFinance Stream Simulator\r\n\r\nUsage:  java -jar FinanceStreamSimulator.jar [--serverUrl=<URL>] [--numberOfMessages=<messages>] [--basePrice=<price>] [--scale=<scale>]\r\n\r\n\r\n2015-08-24 04:16:38.055  INFO 9954 --- [           main] io.pivotal.demo.SimulatorApp             : Starting SimulatorApp on stocks-vm with PID 9954 (/home/vagrant/project/StockInference-Spark/FinanceStreamSimulator/build/classes/main started by vagrant in /home/vagrant/project/StockInference-Spark/FinanceStreamSimulator)\r\n2015-08-24 04:16:38.096  INFO 9954 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@51e2adc7: startup date [Mon Aug 24 04:16:38 UTC 2015]; root of context hierarchy\r\n2015-08-24 04:16:38.847  INFO 9954 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup\r\n2015-08-24 04:16:38.852  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : --------------------------------------\r\n2015-08-24 04:16:38.853  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : >>> Geode rest endpoint: http://localhost:8888\r\n2015-08-24 04:16:38.853  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : >>> Endpoint URL: http://localhost:9000\r\n2015-08-24 04:16:38.853  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : >>> Number of messages: 500\r\n2015-08-24 04:16:38.854  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : >>> Symbol: TSLA\r\n2015-08-24 04:16:38.854  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : --------------------------------------\r\n2015-08-24 04:16:39.240  INFO 9954 --- [           main] io.pivotal.demo.ReplaySimulator          : >>> Posting 500 messages 2015-08-24 04:21:20.768  INFO 10187 --- [           main] io.pivotal.demo.ReplaySimulator          : done\r\n2015-08-24 04:21:20.769  INFO 10187 --- [           main] io.pivotal.demo.SimulatorApp             : Started SimulatorApp in 154.355 seconds (JVM running for 154.685)\r\n2015-08-24 04:21:20.772  INFO 10187 --- [       Thread-1] s.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@51e2adc7: startup date [Mon Aug 24 04:18:46 UTC 2015]; root of context hierarchy\r\n2015-08-24 04:21:20.773  INFO 10187 --- [       Thread-1] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown\r\n\r\nBUILD SUCCESSFUL\r\n\r\nTotal time: 2 mins 38.003 secs\r\n\r\n```\r\n\r\n### Verifying the calculated predictions \r\n\r\nUse GFSH to connect to Geode/GemFire and verify the Predictions region:\r\n\r\n```\r\n$ gfsh\r\n    _________________________     __\r\n   / _____/ ______/ ______/ /____/ /\r\n  / /  __/ /___  /_____  / _____  /\r\n / /__/ / ____/  _____/ / /    / /\r\n/______/_/      /______/_/    /_/    v1.0.0-incubating-SNAPSHOT\r\n\r\nMonitor and Manage GemFire\r\ngfsh> connect --locator=192.168.56.10[10334]\r\nConnecting to Locator at [host=192.168.56.10, port=10334] ..\r\nConnecting to Manager at [host=192.168.56.10, port=1099] ..\r\nSuccessfully connected to: [host=192.168.56.10, port=1099]\r\n\r\ngfsh>describe region --name=/Predictions\r\n..........................................................\r\nName            : Predictions\r\nData Policy     : partition\r\nHosting Members : server1\r\n\r\nNon-Default Attributes Shared By Hosting Members\r\n\r\n Type  |    Name     | Value\r\n------ | ----------- | ---------\r\nRegion | size        | 500\r\n       | data-policy | PARTITION\r\n\r\n```\r\n\r\nNow check some of the data:\r\n\r\n```\r\ngfsh>query --query=\"select entryTimestamp, ema, predicted from /Predictions order by entryTimestamp desc\"\r\n\r\nResult     : true\r\nstartCount : 0\r\nendCount   : 20\r\nRows       : 548\r\n\r\nentryTimestamp |       ema        | predicted\r\n-------------- | ---------------- | ------------------\r\n13353015247329 | 243.655200392179 | 244.36126012453593\r\n13352705066802 | 243.304022701552 | 244.4679070450193\r\n13352402037135 | 242.724916646386 | 243.45581253816388\r\n13352098169940 | 242.36154257993  | 243.70099081921597\r\n13351795573541 | 241.695218711637 | 238.62424186981085\r\n13351492002111 | 243.225267310611 | 244.00046225381527\r\n13351189015085 | 242.839771151012 | 242.8768374516088\r\n13350884494287 | 242.82194251399  | 240.2610870520309\r\n13350573308646 | 244.09792973193  | 246.75466201448913\r\n13350268197871 | 242.775025233505 | 240.11608047958853\r\n13349964892135 | 244.100586370887 | 244.7387182131781\r\n13349658440285 | 243.782938889622 | 243.34998938877558\r\n13349354287691 | 243.999147524282 | 243.42056117407438\r\n13349043851852 | 244.287846987753 | 245.56848677338888\r\n13348734159759 | 243.650035229633 | 243.8471030722387\r\n13348413390251 | 243.552265288641 | 244.84555218518653\r\n13348104692176 | 242.908324243737 | 244.77470961584862\r\n13347800579225 | 241.979062973214 | 238.83273528756686\r\n13347496878110 | 243.547743641872 | 243.66095598690484\r\n13347193662872 | 243.491708904    | 242.94782444029957\r\n13346886510828 | 243.763199762867 | 243.0980329260479\r\n(...)\r\n```\r\nYou can check how accurate the predicted value is by comparing the __ema__ and __predicted__ columns\r\n\r\n### EXTRA: Checking the predictions in real-time using the GUI\r\n\r\nps: If you're using the provided VM, you'll need to clone this repository in your local environment to use the Java Rich UI.\r\n\r\nFrom the directory ``JavaFXClient``, edit the file ``src/main/resources/client.xml`` to point the GemFire/Geode native client to where you're running the servers.\r\nIf you're using the provided VM, this should be the VM IP (192.168.56.10).. otherwise, if you're running it local just use localhost.\r\n\r\n\r\n```\r\nJavaFXClient $ more src/main/resources/client.xml\r\n<?xml version=\"1.0\"?>\r\n<!DOCTYPE client-cache PUBLIC\r\n        \"-//GemStone Systems, Inc.//GemFire Declarative Caching 8.0//EN\"\r\n        \"http://www.gemstone.com/dtd/cache8_0.dtd\">\r\n\r\n<client-cache>\r\n    <pool name=\"client\" subscription-enabled=\"true\">\r\n        <locator host=\"192.168.56.10\" port=\"10334\" /> <!-- CHANGE THE IP ON THIS LINE TO POINT TO GEODE/GEMFIRE -->\r\n    </pool>\r\n\r\n    <region name=\"Stocks\">\r\n        <region-attributes refid=\"PROXY\">\r\n            <cache-listener>\r\n                <class-name>io.pivotal.demo.StockListener</class-name>\r\n            </cache-listener>\r\n        </region-attributes>\r\n    </region>\r\n\r\n    <region name=\"Predictions\">\r\n        <region-attributes refid=\"PROXY\">\r\n            <cache-listener>\r\n                <class-name>io.pivotal.demo.PredictionListener</class-name>\r\n            </cache-listener>\r\n        </region-attributes>\r\n    </region>\r\n</client-cache>\r\n\r\n```\r\nStart the GUI:\r\n\r\n```\r\nJavaFXClient $ ./gradlew run\r\n:compileJava UP-TO-DATE\r\n:processResources UP-TO-DATE\r\n:classes UP-TO-DATE\r\n:runfx\r\n(...)\r\n\r\n```\r\nThis should open the Java based UI. Now run the simulator again, and watch the predicted and real values being plotted in real-time!\r\n\r\n![GUI](gui.png)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}